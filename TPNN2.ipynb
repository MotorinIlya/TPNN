{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yGopnNADN3y",
        "outputId": "57905bb1-5294-40a9-8d4d-9e63b0547f0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  drive/MyDrive/default+of+credit+card+clients.zip\n",
            " extracting: data/default of credit card clients.xls  \n"
          ]
        }
      ],
      "source": [
        "!unzip drive/MyDrive/default+of+credit+card+clients.zip -d data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "40-GYUBsDSad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel('/content/data/default of credit card clients.xls', skiprows=1)"
      ],
      "metadata": {
        "id": "JPQR0A1yDm8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaller = StandardScaler()\n",
        "columns_for_normalize = [\"LIMIT_BAL\", \"AGE\", 'BILL_AMT1', 'BILL_AMT2',\n",
        "       'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1',\n",
        "       'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']\n",
        "\n",
        "df_norm = df.copy()\n",
        "df_norm[columns_for_normalize] = scaller.fit_transform(df[columns_for_normalize])\n",
        "df_norm = df_norm.loc[:, df_norm.columns != \"ID\"]"
      ],
      "metadata": {
        "id": "BZzbTR92DnY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feautures = [\"LIMIT_BAL\", 'AGE', \"PAY_0\", 'BILL_AMT1', 'BILL_AMT2',\n",
        "       'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1',\n",
        "       'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']"
      ],
      "metadata": {
        "id": "-R9Xtgf2EJWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def library_calculation(data):\n",
        "    X = data.loc[:, data.columns != \"default payment next month\"]\n",
        "    y = data[\"default payment next month\"]\n",
        "\n",
        "    dtree = DecisionTreeClassifier(random_state=42)\n",
        "    dtree.fit(X, y)\n",
        "\n",
        "    importances = dtree.feature_importances_\n",
        "\n",
        "    imp_df = pd.DataFrame({\"Feature\" : X.columns, \"Importance\" : importances})\n",
        "    imp_df = imp_df.sort_values(by=\"Importance\", ascending=False)\n",
        "    return imp_df"
      ],
      "metadata": {
        "id": "tvPozcX-GGvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feautures = library_calculation(df_norm).head(15)['Feature'].tolist()\n",
        "feautures"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AiAwHqeaGHjj",
        "outputId": "c2f5ce45-38e4-4fad-a201-314e5b265e82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['PAY_0',\n",
              " 'AGE',\n",
              " 'BILL_AMT1',\n",
              " 'LIMIT_BAL',\n",
              " 'BILL_AMT6',\n",
              " 'BILL_AMT2',\n",
              " 'PAY_AMT3',\n",
              " 'PAY_AMT1',\n",
              " 'BILL_AMT3',\n",
              " 'PAY_AMT5',\n",
              " 'PAY_AMT2',\n",
              " 'PAY_AMT6',\n",
              " 'BILL_AMT5',\n",
              " 'BILL_AMT4',\n",
              " 'PAY_AMT4']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_gain_ratio(X, y):\n",
        "\n",
        "    def entropy(target):\n",
        "        _, counts = np.unique(target, return_counts=True)\n",
        "        probabilities = counts / len(target)\n",
        "        return -np.sum(probabilities * np.log2(probabilities + 1e-10))\n",
        "\n",
        "    X = X.loc[:, X.columns != \"default payment next month\"]\n",
        "    gain_ratios = {}\n",
        "    H_T = entropy(y)\n",
        "\n",
        "    for feature in X.columns:\n",
        "        feature_values = X[feature]\n",
        "        H_T_given_A = 0\n",
        "        IV = 0\n",
        "\n",
        "        for value in np.unique(feature_values):\n",
        "            subset_indices = feature_values == value\n",
        "            subset_y = y[subset_indices]\n",
        "            subset_size = len(subset_y)\n",
        "\n",
        "            if subset_size == 0:\n",
        "                continue\n",
        "\n",
        "            H_T_given_A += (subset_size / len(y)) * entropy(subset_y)\n",
        "\n",
        "            prob = subset_size / len(y)\n",
        "            IV -= prob * np.log2(prob + 1e-10)\n",
        "\n",
        "        IG = H_T - H_T_given_A\n",
        "\n",
        "        if IV == 0:\n",
        "            gain_ratio = 0\n",
        "        else:\n",
        "            gain_ratio = IG / IV\n",
        "\n",
        "        gain_ratios[feature] = gain_ratio\n",
        "\n",
        "    return gain_ratios"
      ],
      "metadata": {
        "id": "pZSJfsY-Iwte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gain_ratios = calculate_gain_ratio(df_norm, df_norm['default payment next month'])"
      ],
      "metadata": {
        "id": "Pgpls8aqIyOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gain_ratios"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwxSiSSWNwIQ",
        "outputId": "8144ea5d-04a9-45a9-b798-face6e637032"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'LIMIT_BAL': np.float64(0.004731211965701588),\n",
              " 'SEX': np.float64(0.0011810595525375365),\n",
              " 'EDUCATION': np.float64(0.002798633042210645),\n",
              " 'MARRIAGE': np.float64(0.0008091198463126944),\n",
              " 'AGE': np.float64(0.0007279586790713947),\n",
              " 'PAY_0': np.float64(0.052937699626075405),\n",
              " 'PAY_2': np.float64(0.038402374899222456),\n",
              " 'PAY_3': np.float64(0.029459342312626334),\n",
              " 'PAY_4': np.float64(0.026760156434092266),\n",
              " 'PAY_5': np.float64(0.025486803342993452),\n",
              " 'PAY_6': np.float64(0.021587253921446052),\n",
              " 'BILL_AMT1': np.float64(0.04287204548191936),\n",
              " 'BILL_AMT2': np.float64(0.042841885877182795),\n",
              " 'BILL_AMT3': np.float64(0.042804017348320296),\n",
              " 'BILL_AMT4': np.float64(0.04245733698373595),\n",
              " 'BILL_AMT5': np.float64(0.04193617754100063),\n",
              " 'BILL_AMT6': np.float64(0.04180148382269046),\n",
              " 'PAY_AMT1': np.float64(0.021453406714947925),\n",
              " 'PAY_AMT2': np.float64(0.020471277450910083),\n",
              " 'PAY_AMT3': np.float64(0.0208783228652973),\n",
              " 'PAY_AMT4': np.float64(0.019915771020802213),\n",
              " 'PAY_AMT5': np.float64(0.019968421345674607),\n",
              " 'PAY_AMT6': np.float64(0.020552205486091504)}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_norm[feautures]\n",
        "pd.get_dummies(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, df_norm['default payment next month'], test_size=0.2, random_state=42)\n",
        "model = LogisticRegression(class_weight='balanced', max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred):.2f}\")\n",
        "print(f'F1 score: {f1_score(y_test, y_pred):.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3un42s8DtNa",
        "outputId": "6883626f-31eb-485a-c4f5-83d8114b0e86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.69\n",
            "Recall: 0.64\n",
            "F1 score: 0.47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Perceptron:\n",
        "    def __init__(self, learning_rate=0.01, n_iters=1000, random_state=None):\n",
        "        self.lr = learning_rate\n",
        "        self.n_iters = n_iters\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "        self.random_state = random_state\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        rgen = np.random.RandomState(self.random_state)\n",
        "\n",
        "\n",
        "        n_samples, n_features = X.shape\n",
        "\n",
        "\n",
        "        self.weights = rgen.normal(loc=0.0, scale=0.01, size=n_features)\n",
        "        self.bias = 0.0\n",
        "\n",
        "\n",
        "        for _ in range(self.n_iters):\n",
        "            errors = 0\n",
        "            for idx, x_i in enumerate(X):\n",
        "\n",
        "                linear_output = np.dot(x_i, self.weights) + self.bias\n",
        "\n",
        "                y_pred = self.step_function(linear_output)\n",
        "\n",
        "                update = self.lr * (y[idx] - y_pred)\n",
        "                if update != 0:\n",
        "                    errors += 1\n",
        "                    self.weights += update * x_i\n",
        "                    self.bias += update\n",
        "\n",
        "            if errors == 0:\n",
        "                break\n",
        "\n",
        "    def step_function(self, x):\n",
        "\n",
        "        return np.where(x >= 0, 1, 0)\n",
        "\n",
        "    def predict(self, X):\n",
        "\n",
        "        linear_output = np.dot(X, self.weights) + self.bias\n",
        "        y_pred = self.step_function(linear_output)\n",
        "        return y_pred\n"
      ],
      "metadata": {
        "id": "5tKmcuXEEi32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_np = X_train.values.astype(np.float64)\n",
        "y_train_np = y_train.values.astype(np.int64).flatten()\n",
        "X_test_np = X_test.values.astype(np.float64)\n",
        "y_test_np = y_test.values.astype(np.int64)\n",
        "\n",
        "perseptron = Perceptron()\n",
        "perseptron.fit(X_train_np, y_train_np)\n",
        "y_pred_np = perseptron.predict(X_test_np)\n",
        "\n",
        "print(f\"Accuracy: {accuracy_score(y_test_np, y_pred_np):.2f}\")\n",
        "print(f\"Recall: {recall_score(y_test_np, y_pred_np):.2f}\")\n",
        "print(f'F1 score: {f1_score(y_test_np, y_pred_np):.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67R2LPOTxbKY",
        "outputId": "ac428d96-6a12-435e-bddd-e6262292b8ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.68\n",
            "Recall: 0.13\n",
            "F1 score: 0.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP:\n",
        "    def __init__(self, layer_sizes, learning_rate=0.01, epochs=1000):\n",
        "        self.layer_sizes = layer_sizes\n",
        "        self.lr = learning_rate\n",
        "        self.epochs = epochs\n",
        "        self.weights = []\n",
        "        self.biases = []\n",
        "\n",
        "        for i in range(len(layer_sizes)-1):\n",
        "            scale = np.sqrt(2 / layer_sizes[i])\n",
        "            self.weights.append(np.random.randn(layer_sizes[i], layer_sizes[i+1]) * scale)\n",
        "            self.biases.append(np.zeros(layer_sizes[i+1]))\n",
        "\n",
        "    def leaky_relu(self, x, alpha=0.01):\n",
        "        return np.where(x > 0, x, alpha * x)\n",
        "\n",
        "    def leaky_relu_derivative(self, x, alpha=0.01):\n",
        "        return np.where(x > 0, 1, alpha)\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def sigmoid_derivative(self, x):\n",
        "        return x * (1 - x)\n",
        "\n",
        "    def forward(self, X):\n",
        "        self.activations = [X]\n",
        "        self.z_values = []\n",
        "        for i in range(len(self.weights)):\n",
        "            z = np.dot(self.activations[-1], self.weights[i]) + self.biases[i]\n",
        "            self.z_values.append(z)\n",
        "            activation = self.leaky_relu(z) if i < len(self.weights)-1 else self.sigmoid(z)\n",
        "            self.activations.append(activation)\n",
        "        return self.activations[-1]\n",
        "\n",
        "    def backward(self, y):\n",
        "        m = y.shape[0]\n",
        "        y = y.reshape(-1, 1)\n",
        "        error = self.activations[-1] - y\n",
        "        deltas = [error * self.sigmoid_derivative(self.activations[-1])]\n",
        "\n",
        "        for i in reversed(range(len(self.weights)-1)):\n",
        "            error = np.dot(deltas[-1], self.weights[i+1].T)\n",
        "            delta = error * self.leaky_relu_derivative(self.activations[i+1])\n",
        "            deltas.append(delta)\n",
        "\n",
        "        deltas.reverse()\n",
        "\n",
        "        for i in range(len(self.weights)):\n",
        "            dW = np.dot(self.activations[i].T, deltas[i]) / m\n",
        "            db = np.sum(deltas[i], axis=0) / m\n",
        "            self.weights[i] -= self.lr * dW\n",
        "            self.biases[i] -= self.lr * db\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        for epoch in range(self.epochs):\n",
        "            y_pred = self.forward(X)\n",
        "            self.backward(y)\n",
        "            if epoch % 100 == 0:\n",
        "                loss = np.mean((y_pred - y.reshape(-1, 1))**2)\n",
        "                print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
        "\n",
        "    def predict(self, X, threshold=0.5):\n",
        "        return (self.forward(X) >= threshold).astype(int)"
      ],
      "metadata": {
        "id": "yfr_ZzSN6AcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp = MLP(layer_sizes=[len(feautures), 4, 1], learning_rate=0.1)\n",
        "\n",
        "mlp.fit(X_train_np, y_train_np)\n",
        "y_pred_np = mlp.predict(X_test_np)\n",
        "\n",
        "print(f\"Accuracy: {accuracy_score(y_test_np, y_pred_np):.2f}\")\n",
        "print(f\"Recall: {recall_score(y_test_np, y_pred_np):.2f}\")\n",
        "print(f'F1 score: {f1_score(y_test_np, y_pred_np):.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lr4vAss74nBm",
        "outputId": "770c8e71-147a-425c-c831-d2db34759148"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.3726\n",
            "Epoch 100, Loss: 0.2077\n",
            "Epoch 200, Loss: 0.1875\n",
            "Epoch 300, Loss: 0.1735\n",
            "Epoch 400, Loss: 0.1631\n",
            "Epoch 500, Loss: 0.1554\n",
            "Epoch 600, Loss: 0.1506\n",
            "Epoch 700, Loss: 0.1481\n",
            "Epoch 800, Loss: 0.1468\n",
            "Epoch 900, Loss: 0.1460\n",
            "Accuracy: 0.82\n",
            "Recall: 0.31\n",
            "F1 score: 0.43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, recall_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau"
      ],
      "metadata": {
        "id": "UV_HI2lMT1zZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_mlp(input_shape, num_classes=1):\n",
        "    model = Sequential([\n",
        "        Dense(input_shape, activation='relu', input_shape=(input_shape,)),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        Dense(4, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.2),\n",
        "\n",
        "        Dense(num_classes, activation='sigmoid' if num_classes == 1 else 'softmax')\n",
        "    ])\n",
        "\n",
        "    # Компиляция модели\n",
        "    optimizer = Adam(learning_rate=0.001)\n",
        "    loss = 'binary_crossentropy' if num_classes == 1 else 'categorical_crossentropy'\n",
        "    metrics = ['accuracy', 'Recall']\n",
        "\n",
        "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
        "    return model\n",
        "\n",
        "\n",
        "def train_model(model, X_train, y_train, X_val, y_val, epochs=1000):\n",
        "    callbacks = [\n",
        "        EarlyStopping(monitor='val_recall', patience=10, mode='max', verbose=1),\n",
        "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6)\n",
        "    ]\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_val, y_val),\n",
        "        epochs=epochs,\n",
        "        batch_size=1,\n",
        "        callbacks=callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "    return history\n",
        "\n",
        "# 4. Оценка модели\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(f\"Test Recall: {recall_score(y_test, y_pred):.4f}\")"
      ],
      "metadata": {
        "id": "S93nCBB-R47k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_mlp(len(feautures))\n",
        "train_model(model, X_train_np, y_train_np, X_test_np, y_test_np)\n",
        "evaluate_model(model, X_test_np, y_test_np)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W00L9fSoSNmE",
        "outputId": "90bbca08-1edb-430d-ec6c-4747152bb20d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - Recall: 0.4096 - accuracy: 0.7312 - loss: 0.5791 - val_Recall: 0.3016 - val_accuracy: 0.8188 - val_loss: 0.4473 - learning_rate: 0.0010\n",
            "Epoch 2/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_recall` which is not available. Available metrics are: Recall,accuracy,loss,val_Recall,val_accuracy,val_loss\n",
            "  current = self.get_monitor_value(logs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - Recall: 0.2914 - accuracy: 0.8040 - loss: 0.4729 - val_Recall: 0.3062 - val_accuracy: 0.8195 - val_loss: 0.4458 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - Recall: 0.3211 - accuracy: 0.8124 - loss: 0.4587 - val_Recall: 0.3199 - val_accuracy: 0.8195 - val_loss: 0.4423 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Recall: 0.3298 - accuracy: 0.8159 - loss: 0.4497 - val_Recall: 0.3115 - val_accuracy: 0.8187 - val_loss: 0.4436 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - Recall: 0.3341 - accuracy: 0.8185 - loss: 0.4450 - val_Recall: 0.3123 - val_accuracy: 0.8195 - val_loss: 0.4418 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - Recall: 0.3375 - accuracy: 0.8146 - loss: 0.4464 - val_Recall: 0.3077 - val_accuracy: 0.8172 - val_loss: 0.4406 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - Recall: 0.3330 - accuracy: 0.8205 - loss: 0.4372 - val_Recall: 0.3359 - val_accuracy: 0.8178 - val_loss: 0.4409 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - Recall: 0.3348 - accuracy: 0.8158 - loss: 0.4465 - val_Recall: 0.3153 - val_accuracy: 0.8198 - val_loss: 0.4381 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - Recall: 0.3454 - accuracy: 0.8182 - loss: 0.4412 - val_Recall: 0.3107 - val_accuracy: 0.8175 - val_loss: 0.4395 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Recall: 0.3278 - accuracy: 0.8143 - loss: 0.4476 - val_Recall: 0.3237 - val_accuracy: 0.8210 - val_loss: 0.4392 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - Recall: 0.3383 - accuracy: 0.8193 - loss: 0.4389 - val_Recall: 0.3001 - val_accuracy: 0.8185 - val_loss: 0.4402 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - Recall: 0.3213 - accuracy: 0.8139 - loss: 0.4443 - val_Recall: 0.3206 - val_accuracy: 0.8200 - val_loss: 0.4379 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Recall: 0.3508 - accuracy: 0.8198 - loss: 0.4339 - val_Recall: 0.3092 - val_accuracy: 0.8172 - val_loss: 0.4390 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Recall: 0.3401 - accuracy: 0.8176 - loss: 0.4394 - val_Recall: 0.2986 - val_accuracy: 0.8180 - val_loss: 0.4404 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - Recall: 0.3376 - accuracy: 0.8180 - loss: 0.4400 - val_Recall: 0.3267 - val_accuracy: 0.8180 - val_loss: 0.4365 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - Recall: 0.3319 - accuracy: 0.8155 - loss: 0.4407 - val_Recall: 0.3343 - val_accuracy: 0.8182 - val_loss: 0.4395 - learning_rate: 0.0010\n",
            "Epoch 17/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - Recall: 0.3311 - accuracy: 0.8185 - loss: 0.4374 - val_Recall: 0.3130 - val_accuracy: 0.8203 - val_loss: 0.4408 - learning_rate: 0.0010\n",
            "Epoch 18/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - Recall: 0.3529 - accuracy: 0.8180 - loss: 0.4379 - val_Recall: 0.2978 - val_accuracy: 0.8183 - val_loss: 0.4399 - learning_rate: 0.0010\n",
            "Epoch 19/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - Recall: 0.3436 - accuracy: 0.8185 - loss: 0.4404 - val_Recall: 0.3046 - val_accuracy: 0.8185 - val_loss: 0.4380 - learning_rate: 0.0010\n",
            "Epoch 20/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Recall: 0.3386 - accuracy: 0.8154 - loss: 0.4403 - val_Recall: 0.2963 - val_accuracy: 0.8187 - val_loss: 0.4392 - learning_rate: 0.0010\n",
            "Epoch 21/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - Recall: 0.3182 - accuracy: 0.8184 - loss: 0.4369 - val_Recall: 0.3138 - val_accuracy: 0.8192 - val_loss: 0.4362 - learning_rate: 2.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - Recall: 0.3556 - accuracy: 0.8176 - loss: 0.4347 - val_Recall: 0.3138 - val_accuracy: 0.8198 - val_loss: 0.4363 - learning_rate: 2.0000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Recall: 0.3414 - accuracy: 0.8175 - loss: 0.4373 - val_Recall: 0.3077 - val_accuracy: 0.8187 - val_loss: 0.4364 - learning_rate: 2.0000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Recall: 0.3519 - accuracy: 0.8226 - loss: 0.4302 - val_Recall: 0.3214 - val_accuracy: 0.8187 - val_loss: 0.4352 - learning_rate: 2.0000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - Recall: 0.3565 - accuracy: 0.8212 - loss: 0.4319 - val_Recall: 0.3176 - val_accuracy: 0.8183 - val_loss: 0.4349 - learning_rate: 2.0000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - Recall: 0.3385 - accuracy: 0.8172 - loss: 0.4356 - val_Recall: 0.3222 - val_accuracy: 0.8197 - val_loss: 0.4350 - learning_rate: 2.0000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Recall: 0.3343 - accuracy: 0.8176 - loss: 0.4343 - val_Recall: 0.3176 - val_accuracy: 0.8203 - val_loss: 0.4347 - learning_rate: 2.0000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Recall: 0.3478 - accuracy: 0.8200 - loss: 0.4296 - val_Recall: 0.3138 - val_accuracy: 0.8200 - val_loss: 0.4349 - learning_rate: 2.0000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Recall: 0.3475 - accuracy: 0.8209 - loss: 0.4285 - val_Recall: 0.3161 - val_accuracy: 0.8200 - val_loss: 0.4351 - learning_rate: 2.0000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - Recall: 0.3510 - accuracy: 0.8204 - loss: 0.4311 - val_Recall: 0.3145 - val_accuracy: 0.8197 - val_loss: 0.4348 - learning_rate: 2.0000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Recall: 0.3447 - accuracy: 0.8197 - loss: 0.4336 - val_Recall: 0.3092 - val_accuracy: 0.8193 - val_loss: 0.4348 - learning_rate: 2.0000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Recall: 0.3441 - accuracy: 0.8193 - loss: 0.4306 - val_Recall: 0.3115 - val_accuracy: 0.8195 - val_loss: 0.4348 - learning_rate: 2.0000e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - Recall: 0.3442 - accuracy: 0.8210 - loss: 0.4291 - val_Recall: 0.3115 - val_accuracy: 0.8195 - val_loss: 0.4344 - learning_rate: 4.0000e-05\n",
            "Epoch 34/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - Recall: 0.3368 - accuracy: 0.8164 - loss: 0.4389 - val_Recall: 0.3130 - val_accuracy: 0.8198 - val_loss: 0.4346 - learning_rate: 4.0000e-05\n",
            "Epoch 35/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - Recall: 0.3585 - accuracy: 0.8203 - loss: 0.4365 - val_Recall: 0.3115 - val_accuracy: 0.8193 - val_loss: 0.4348 - learning_rate: 4.0000e-05\n",
            "Epoch 36/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - Recall: 0.3429 - accuracy: 0.8186 - loss: 0.4318 - val_Recall: 0.3130 - val_accuracy: 0.8198 - val_loss: 0.4344 - learning_rate: 4.0000e-05\n",
            "Epoch 37/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - Recall: 0.3383 - accuracy: 0.8207 - loss: 0.4280 - val_Recall: 0.3130 - val_accuracy: 0.8198 - val_loss: 0.4342 - learning_rate: 4.0000e-05\n",
            "Epoch 38/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Recall: 0.3474 - accuracy: 0.8160 - loss: 0.4420 - val_Recall: 0.3145 - val_accuracy: 0.8197 - val_loss: 0.4342 - learning_rate: 4.0000e-05\n",
            "Epoch 39/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - Recall: 0.3537 - accuracy: 0.8219 - loss: 0.4281 - val_Recall: 0.3145 - val_accuracy: 0.8200 - val_loss: 0.4345 - learning_rate: 4.0000e-05\n",
            "Epoch 40/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - Recall: 0.3486 - accuracy: 0.8213 - loss: 0.4338 - val_Recall: 0.3184 - val_accuracy: 0.8193 - val_loss: 0.4341 - learning_rate: 4.0000e-05\n",
            "Epoch 41/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Recall: 0.3531 - accuracy: 0.8216 - loss: 0.4309 - val_Recall: 0.3145 - val_accuracy: 0.8195 - val_loss: 0.4342 - learning_rate: 4.0000e-05\n",
            "Epoch 42/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Recall: 0.3334 - accuracy: 0.8172 - loss: 0.4340 - val_Recall: 0.3138 - val_accuracy: 0.8200 - val_loss: 0.4341 - learning_rate: 4.0000e-05\n",
            "Epoch 43/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - Recall: 0.3466 - accuracy: 0.8181 - loss: 0.4369 - val_Recall: 0.3115 - val_accuracy: 0.8195 - val_loss: 0.4347 - learning_rate: 4.0000e-05\n",
            "Epoch 44/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - Recall: 0.3621 - accuracy: 0.8233 - loss: 0.4307 - val_Recall: 0.3145 - val_accuracy: 0.8195 - val_loss: 0.4342 - learning_rate: 4.0000e-05\n",
            "Epoch 45/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - Recall: 0.3599 - accuracy: 0.8210 - loss: 0.4304 - val_Recall: 0.3176 - val_accuracy: 0.8193 - val_loss: 0.4342 - learning_rate: 4.0000e-05\n",
            "Epoch 46/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - Recall: 0.3460 - accuracy: 0.8209 - loss: 0.4317 - val_Recall: 0.3161 - val_accuracy: 0.8192 - val_loss: 0.4341 - learning_rate: 8.0000e-06\n",
            "Epoch 47/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - Recall: 0.3502 - accuracy: 0.8205 - loss: 0.4286 - val_Recall: 0.3176 - val_accuracy: 0.8193 - val_loss: 0.4340 - learning_rate: 8.0000e-06\n",
            "Epoch 48/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - Recall: 0.3378 - accuracy: 0.8150 - loss: 0.4335 - val_Recall: 0.3176 - val_accuracy: 0.8195 - val_loss: 0.4339 - learning_rate: 8.0000e-06\n",
            "Epoch 49/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - Recall: 0.3498 - accuracy: 0.8182 - loss: 0.4359 - val_Recall: 0.3176 - val_accuracy: 0.8197 - val_loss: 0.4342 - learning_rate: 8.0000e-06\n",
            "Epoch 50/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Recall: 0.3558 - accuracy: 0.8228 - loss: 0.4269 - val_Recall: 0.3161 - val_accuracy: 0.8197 - val_loss: 0.4342 - learning_rate: 8.0000e-06\n",
            "Epoch 51/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - Recall: 0.3397 - accuracy: 0.8186 - loss: 0.4310 - val_Recall: 0.3153 - val_accuracy: 0.8203 - val_loss: 0.4342 - learning_rate: 8.0000e-06\n",
            "Epoch 52/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - Recall: 0.3371 - accuracy: 0.8187 - loss: 0.4310 - val_Recall: 0.3130 - val_accuracy: 0.8193 - val_loss: 0.4339 - learning_rate: 8.0000e-06\n",
            "Epoch 53/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Recall: 0.3490 - accuracy: 0.8216 - loss: 0.4263 - val_Recall: 0.3184 - val_accuracy: 0.8195 - val_loss: 0.4339 - learning_rate: 8.0000e-06\n",
            "Epoch 54/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Recall: 0.3462 - accuracy: 0.8199 - loss: 0.4276 - val_Recall: 0.3115 - val_accuracy: 0.8195 - val_loss: 0.4347 - learning_rate: 1.6000e-06\n",
            "Epoch 55/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Recall: 0.3425 - accuracy: 0.8216 - loss: 0.4280 - val_Recall: 0.3130 - val_accuracy: 0.8195 - val_loss: 0.4342 - learning_rate: 1.6000e-06\n",
            "Epoch 56/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Recall: 0.3396 - accuracy: 0.8157 - loss: 0.4351 - val_Recall: 0.3123 - val_accuracy: 0.8197 - val_loss: 0.4345 - learning_rate: 1.6000e-06\n",
            "Epoch 57/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - Recall: 0.3514 - accuracy: 0.8232 - loss: 0.4275 - val_Recall: 0.3176 - val_accuracy: 0.8197 - val_loss: 0.4340 - learning_rate: 1.6000e-06\n",
            "Epoch 58/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Recall: 0.3579 - accuracy: 0.8250 - loss: 0.4283 - val_Recall: 0.3138 - val_accuracy: 0.8200 - val_loss: 0.4344 - learning_rate: 1.6000e-06\n",
            "Epoch 59/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Recall: 0.3501 - accuracy: 0.8190 - loss: 0.4333 - val_Recall: 0.3153 - val_accuracy: 0.8203 - val_loss: 0.4341 - learning_rate: 1.0000e-06\n",
            "Epoch 60/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Recall: 0.3489 - accuracy: 0.8181 - loss: 0.4301 - val_Recall: 0.3153 - val_accuracy: 0.8190 - val_loss: 0.4343 - learning_rate: 1.0000e-06\n",
            "Epoch 61/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - Recall: 0.3570 - accuracy: 0.8256 - loss: 0.4235 - val_Recall: 0.3145 - val_accuracy: 0.8202 - val_loss: 0.4341 - learning_rate: 1.0000e-06\n",
            "Epoch 62/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Recall: 0.3512 - accuracy: 0.8216 - loss: 0.4266 - val_Recall: 0.3161 - val_accuracy: 0.8202 - val_loss: 0.4344 - learning_rate: 1.0000e-06\n",
            "Epoch 63/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - Recall: 0.3463 - accuracy: 0.8207 - loss: 0.4285 - val_Recall: 0.3145 - val_accuracy: 0.8200 - val_loss: 0.4342 - learning_rate: 1.0000e-06\n",
            "Epoch 64/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - Recall: 0.3474 - accuracy: 0.8191 - loss: 0.4306 - val_Recall: 0.3184 - val_accuracy: 0.8195 - val_loss: 0.4345 - learning_rate: 1.0000e-06\n",
            "Epoch 65/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - Recall: 0.3496 - accuracy: 0.8229 - loss: 0.4276 - val_Recall: 0.3130 - val_accuracy: 0.8198 - val_loss: 0.4345 - learning_rate: 1.0000e-06\n",
            "Epoch 66/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - Recall: 0.3455 - accuracy: 0.8188 - loss: 0.4319 - val_Recall: 0.3130 - val_accuracy: 0.8198 - val_loss: 0.4341 - learning_rate: 1.0000e-06\n",
            "Epoch 67/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Recall: 0.3567 - accuracy: 0.8200 - loss: 0.4312 - val_Recall: 0.3145 - val_accuracy: 0.8202 - val_loss: 0.4340 - learning_rate: 1.0000e-06\n",
            "Epoch 68/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - Recall: 0.3422 - accuracy: 0.8181 - loss: 0.4328 - val_Recall: 0.3161 - val_accuracy: 0.8198 - val_loss: 0.4347 - learning_rate: 1.0000e-06\n",
            "Epoch 69/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - Recall: 0.3569 - accuracy: 0.8206 - loss: 0.4303 - val_Recall: 0.3161 - val_accuracy: 0.8193 - val_loss: 0.4341 - learning_rate: 1.0000e-06\n",
            "Epoch 70/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Recall: 0.3595 - accuracy: 0.8214 - loss: 0.4316 - val_Recall: 0.3123 - val_accuracy: 0.8197 - val_loss: 0.4347 - learning_rate: 1.0000e-06\n",
            "Epoch 71/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Recall: 0.3425 - accuracy: 0.8148 - loss: 0.4391 - val_Recall: 0.3145 - val_accuracy: 0.8198 - val_loss: 0.4347 - learning_rate: 1.0000e-06\n",
            "Epoch 72/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - Recall: 0.3575 - accuracy: 0.8209 - loss: 0.4308 - val_Recall: 0.3138 - val_accuracy: 0.8200 - val_loss: 0.4342 - learning_rate: 1.0000e-06\n",
            "Epoch 73/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - Recall: 0.3501 - accuracy: 0.8191 - loss: 0.4298 - val_Recall: 0.3138 - val_accuracy: 0.8197 - val_loss: 0.4346 - learning_rate: 1.0000e-06\n",
            "Epoch 74/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Recall: 0.3411 - accuracy: 0.8182 - loss: 0.4311 - val_Recall: 0.3184 - val_accuracy: 0.8195 - val_loss: 0.4339 - learning_rate: 1.0000e-06\n",
            "Epoch 75/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - Recall: 0.3418 - accuracy: 0.8195 - loss: 0.4357 - val_Recall: 0.3145 - val_accuracy: 0.8197 - val_loss: 0.4339 - learning_rate: 1.0000e-06\n",
            "Epoch 76/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - Recall: 0.3492 - accuracy: 0.8178 - loss: 0.4358 - val_Recall: 0.3138 - val_accuracy: 0.8195 - val_loss: 0.4346 - learning_rate: 1.0000e-06\n",
            "Epoch 77/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Recall: 0.3387 - accuracy: 0.8160 - loss: 0.4367 - val_Recall: 0.3130 - val_accuracy: 0.8195 - val_loss: 0.4341 - learning_rate: 1.0000e-06\n",
            "Epoch 78/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - Recall: 0.3469 - accuracy: 0.8202 - loss: 0.4311 - val_Recall: 0.3123 - val_accuracy: 0.8198 - val_loss: 0.4342 - learning_rate: 1.0000e-06\n",
            "Epoch 79/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - Recall: 0.3377 - accuracy: 0.8154 - loss: 0.4323 - val_Recall: 0.3123 - val_accuracy: 0.8198 - val_loss: 0.4342 - learning_rate: 1.0000e-06\n",
            "Epoch 80/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - Recall: 0.3529 - accuracy: 0.8221 - loss: 0.4293 - val_Recall: 0.3138 - val_accuracy: 0.8198 - val_loss: 0.4340 - learning_rate: 1.0000e-06\n",
            "Epoch 81/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - Recall: 0.3452 - accuracy: 0.8199 - loss: 0.4303 - val_Recall: 0.3130 - val_accuracy: 0.8195 - val_loss: 0.4338 - learning_rate: 1.0000e-06\n",
            "Epoch 82/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Recall: 0.3529 - accuracy: 0.8224 - loss: 0.4250 - val_Recall: 0.3191 - val_accuracy: 0.8190 - val_loss: 0.4342 - learning_rate: 1.0000e-06\n",
            "Epoch 83/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - Recall: 0.3477 - accuracy: 0.8190 - loss: 0.4322 - val_Recall: 0.3138 - val_accuracy: 0.8192 - val_loss: 0.4343 - learning_rate: 1.0000e-06\n",
            "Epoch 84/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - Recall: 0.3396 - accuracy: 0.8163 - loss: 0.4382 - val_Recall: 0.3138 - val_accuracy: 0.8198 - val_loss: 0.4342 - learning_rate: 1.0000e-06\n",
            "Epoch 85/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Recall: 0.3400 - accuracy: 0.8159 - loss: 0.4333 - val_Recall: 0.3115 - val_accuracy: 0.8195 - val_loss: 0.4349 - learning_rate: 1.0000e-06\n",
            "Epoch 86/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Recall: 0.3480 - accuracy: 0.8171 - loss: 0.4354 - val_Recall: 0.3153 - val_accuracy: 0.8195 - val_loss: 0.4344 - learning_rate: 1.0000e-06\n",
            "Epoch 87/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - Recall: 0.3522 - accuracy: 0.8181 - loss: 0.4305 - val_Recall: 0.3100 - val_accuracy: 0.8193 - val_loss: 0.4352 - learning_rate: 1.0000e-06\n",
            "Epoch 88/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - Recall: 0.3592 - accuracy: 0.8219 - loss: 0.4286 - val_Recall: 0.3184 - val_accuracy: 0.8190 - val_loss: 0.4339 - learning_rate: 1.0000e-06\n",
            "Epoch 89/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - Recall: 0.3564 - accuracy: 0.8187 - loss: 0.4376 - val_Recall: 0.3123 - val_accuracy: 0.8197 - val_loss: 0.4344 - learning_rate: 1.0000e-06\n",
            "Epoch 90/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - Recall: 0.3512 - accuracy: 0.8176 - loss: 0.4305 - val_Recall: 0.3184 - val_accuracy: 0.8190 - val_loss: 0.4342 - learning_rate: 1.0000e-06\n",
            "Epoch 91/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - Recall: 0.3449 - accuracy: 0.8178 - loss: 0.4312 - val_Recall: 0.3222 - val_accuracy: 0.8193 - val_loss: 0.4340 - learning_rate: 1.0000e-06\n",
            "Epoch 92/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - Recall: 0.3439 - accuracy: 0.8175 - loss: 0.4357 - val_Recall: 0.3123 - val_accuracy: 0.8195 - val_loss: 0.4351 - learning_rate: 1.0000e-06\n",
            "Epoch 93/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - Recall: 0.3425 - accuracy: 0.8165 - loss: 0.4376 - val_Recall: 0.3130 - val_accuracy: 0.8190 - val_loss: 0.4342 - learning_rate: 1.0000e-06\n",
            "Epoch 94/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - Recall: 0.3471 - accuracy: 0.8187 - loss: 0.4338 - val_Recall: 0.3115 - val_accuracy: 0.8195 - val_loss: 0.4345 - learning_rate: 1.0000e-06\n",
            "Epoch 95/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - Recall: 0.3469 - accuracy: 0.8181 - loss: 0.4306 - val_Recall: 0.3222 - val_accuracy: 0.8193 - val_loss: 0.4339 - learning_rate: 1.0000e-06\n",
            "Epoch 96/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - Recall: 0.3439 - accuracy: 0.8183 - loss: 0.4344 - val_Recall: 0.3184 - val_accuracy: 0.8195 - val_loss: 0.4340 - learning_rate: 1.0000e-06\n",
            "Epoch 97/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - Recall: 0.3386 - accuracy: 0.8150 - loss: 0.4399 - val_Recall: 0.3123 - val_accuracy: 0.8198 - val_loss: 0.4344 - learning_rate: 1.0000e-06\n",
            "Epoch 98/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - Recall: 0.3471 - accuracy: 0.8177 - loss: 0.4339 - val_Recall: 0.3168 - val_accuracy: 0.8193 - val_loss: 0.4343 - learning_rate: 1.0000e-06\n",
            "Epoch 99/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - Recall: 0.3553 - accuracy: 0.8200 - loss: 0.4308 - val_Recall: 0.3184 - val_accuracy: 0.8197 - val_loss: 0.4343 - learning_rate: 1.0000e-06\n",
            "Epoch 100/100\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - Recall: 0.3554 - accuracy: 0.8210 - loss: 0.4300 - val_Recall: 0.3153 - val_accuracy: 0.8190 - val_loss: 0.4338 - learning_rate: 1.0000e-06\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.96      0.89      4687\n",
            "           1       0.69      0.32      0.43      1313\n",
            "\n",
            "    accuracy                           0.82      6000\n",
            "   macro avg       0.76      0.64      0.66      6000\n",
            "weighted avg       0.80      0.82      0.79      6000\n",
            "\n",
            "Test Recall: 0.3153\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dIu8na7pVqSs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}